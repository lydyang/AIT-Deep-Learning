{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lydyang/AIT-Deep-Learning/blob/main/Lydia_Yang_AIT_NLP_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<pre>\n",
        "Modified version of: https://github.com/muntasirhsn/Retrieval-Augmented-Generation-with-Llama-2/blob/main/RAG_with_Lama_2_and_LangChain_2.ipynb\n",
        "\n",
        "Modified and updated by:  B√°lint Gyires-T√≥th\n",
        "</pre>"
      ],
      "metadata": {
        "id": "UVidPYdKozjF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce4-y4JJgVSv"
      },
      "source": [
        "# RAG + LLM Assessment\n",
        "Your task is to create a Retrieval-Augmented Generation (RAG) system using a Large Language Model (LLM). The RAG system should be able to retrieve relevant information from a knowledge base and generate coherent and informative responses to user queries.\n",
        "\n",
        "Steps:\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "1. Choose a domain and collect a suitable dataset of documents (at least 5 documents - PDFs or HTML pages) to serve as the knowledge base for your RAG system. Select one of the following topics:\n",
        "   * latest scientific papers from arxiv.org,\n",
        "   * fiction books released,\n",
        "   * legal documentsor,\n",
        "   * social media posts.\n",
        "\n",
        "   Make sure that the documents are newer then the training dataset of the applied LLM. (20 points)\n",
        "\n",
        "2. Create three relevant prompts to the dataset, and one irrelevant prompt. (20 points)\n",
        "\n",
        "3. Load an LLM with at least 5B parameters. (10 points)\n",
        "\n",
        "4. Test the LLM with your prompts. The goal should be that without the collected dataset your model is unable to answer the question. If it gives you a good answer, select another question to answer and maybe a different dataset. (10 points)\n",
        "\n",
        "5. Create a LangChain-based RAG system by setting up a vector database from the documents. (20 points)\n",
        "\n",
        "6. Provide your three relevant and one irrelevant prompts to your RAG system. For the relevant prompts, your RAG system should return relevant answers, and for the irrelevant prompt, an empty answer. (20 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Domain and Data\n",
        "I picked five LinkedIn posts from 2024 to use as my dataset.\n",
        "* https://www.linkedin.com/posts/robschluensen_hello-fall-2024-andor-spring-2025-computer-activity-7191611032388132864-q8J3?utm_source=combined_share_message&utm_medium=member_desktop\n",
        "\n",
        "* https://www.linkedin.com/posts/seth-ingall-20ab71226_last-fall-after-more-than-3-decades-of-service-activity-7193585428199809024-gJhT?utm_source=combined_share_message&utm_medium=member_desktop\n",
        "\n",
        "* https://www.linkedin.com/posts/costafilhoe_fully-funded-phd-student-position-at-south-activity-7184803939345727488-pUDS?utm_source=combined_share_message&utm_medium=member_desktop\n",
        "\n",
        "* https://www.linkedin.com/posts/xiao-kuang-9aa578184_scientist-xiao-kuang-activity-7193411289589723137-vD7O?utm_source=combined_share_message&utm_medium=member_desktop\n",
        "\n",
        "* https://www.linkedin.com/posts/seungdeog-choi-b0a7246_pees-lab-activity-7193383940835995648-b1cp?utm_source=combined_share_message&utm_medium=member_desktop\n",
        "\n"
      ],
      "metadata": {
        "id": "vQS2akEu-QB2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Prompts\n",
        "My relevant prompts are:\n",
        "\n",
        "1.   \"Who sent the LinkedIn post 3 weeks ago in April 2024 for a fully-funded Ph.D. student position in ecohydrology and remote sensing, starting in Spring 2025 at South Dakota School of Mines, Rapid City, SD.?\"\n",
        "2.   \"After how many years did Seth Ingall serve before depart from GEICO in spring of 2024?\"\n",
        "3. \"Who sent the LinkedIn post for a Full-Stack Software Engineering Intern role for the IT Business System Engineering team in Fall 2024 and/or Spring 2025 Computer Science students?\"\n",
        "\n",
        "My irrelevant prompt is:\n",
        "\n",
        "1. \"What color are my shoes today?\""
      ],
      "metadata": {
        "id": "7WPSP__lbHVg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPpiHVgj4CmG"
      },
      "source": [
        "# 3. Load the LLM\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zjLkm65J_S0v"
      },
      "outputs": [],
      "source": [
        "!pip install transformers>=4.32.0 optimum>=1.12.0 > null\n",
        "!pip install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu118/ > null\n",
        "!pip install langchain > null\n",
        "!pip install chromadb > null\n",
        "!pip install sentence_transformers > null # ==2.2.2\n",
        "!pip install unstructured > null\n",
        "!pip install pdf2image > null\n",
        "!pip install pdfminer.six > null\n",
        "!pip install unstructured-pytesseract > null\n",
        "!pip install unstructured-inference > null\n",
        "!pip install faiss-gpu > null\n",
        "!pip install pikepdf > null\n",
        "!pip install pypdf > null\n",
        "!pip install accelerate > null\n",
        "!pip install pillow_heif > null\n",
        "!pip install -i https://pypi.org/simple/ bitsandbytes > null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "qEb7_aQ50Y-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PatG1bZXGOws",
        "outputId": "c3693289-f29e-47e0-afe4-186878e6fc98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline, BitsAndBytesConfig\n",
        "from textwrap import fill\n",
        "from langchain.prompts import PromptTemplate\n",
        "import locale\n",
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "from langchain.vectorstores.utils import filter_complex_metadata # 'filter_complex_metadata' removes complex metadata that are not in str, int, float or bool format\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "# you need to define your private User Access Token from Huggingface\n",
        "# to be able to access models with accepted licence\n",
        "HUGGINGFACE_UAT=\"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\"\n",
        "login(HUGGINGFACE_UAT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "N_hQ_IfuoWT6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222,
          "referenced_widgets": [
            "50facd2c87c242e0ac0bf86a3e405d98",
            "fb0941ce1a8642d7a2e4d74a9dfc62a2",
            "2a4d9448a7384dc693b18352c3e20356",
            "bf4f67aaed95470a976e9a62e11ff313",
            "4fb431e30a8b42cea90de3b269d1bddb",
            "f1d205e34a0347b293a7d5975211ca0a",
            "52b89f64e12a463fb5cffa78438005a4",
            "b0cb6df62cd141338969111d4440e7bf",
            "b76b87424b9f4b70b0c9e9c55db5e584",
            "0a084fdb4f194e60a7ee2a705834b3a6",
            "629627ef06c647c08f5786696de8d3ef"
          ]
        },
        "outputId": "762b739c-dc2c-4f9e-8127-43d0f2f4a46b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50facd2c87c242e0ac0bf86a3e405d98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\" # 8B language model from Meta AI\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
        "                                             device_map=\"auto\",\n",
        "                                             quantization_config=quantization_config,\n",
        "                                             trust_remote_code=True)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "\n",
        "gen_cfg = GenerationConfig.from_pretrained(model_name)\n",
        "gen_cfg.max_new_tokens=512\n",
        "gen_cfg.temperature=0.0000001 # 0.0 # For RAG we would like to have determenistic answers\n",
        "gen_cfg.return_full_text=True\n",
        "gen_cfg.do_sample=True\n",
        "gen_cfg.repetition_penalty=1.11\n",
        "\n",
        "pipe=pipeline(\n",
        "    task=\"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    generation_config=gen_cfg\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=pipe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R69LfWsnYAqk"
      },
      "source": [
        "# 4. Testing the LLM with My Prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BX6bnnL45a2N"
      },
      "outputs": [],
      "source": [
        "template_llama3 = \"\"\"\n",
        "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "{text}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\"\"\"\n",
        "\n",
        "template=template_llama3\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"text\"],\n",
        "    template=template,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Who sent the LinkedIn post 3 weeks ago in April 2024 for a fully-funded Ph.D. student position in ecohydrology and remote sensing, starting in Spring 2025 at South Dakota School of Mines, Rapid City, SD.?\"\n",
        "result = llm(prompt.format(text=text))\n",
        "print(fill(result.strip(), width=100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycLeJ2TOUNgH",
        "outputId": "24b7f848-cee5-4f26-8b76-b3fd5d662917"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>user<|end_header_id|>  Who sent the LinkedIn post 3 weeks ago in\n",
            "April 2024 for a fully-funded Ph.D. student position in ecohydrology and remote sensing, starting in\n",
            "Spring 2025 at South Dakota School of Mines, Rapid City,\n",
            "SD.?<|eot_id|><|start_header_id|>assistant<|end_header_id|> I'm not aware of any specific LinkedIn\n",
            "post that was sent three weeks ago in April 2024 for a fully-funded Ph.D. student position in\n",
            "ecohydrology and remote sensing at South Dakota School of Mines, Rapid City, SD.  It's possible that\n",
            "you may have missed the post or it might be a private message or an email that wasn't shared\n",
            "publicly on LinkedIn. Additionally, job postings can be removed or updated frequently, so even if\n",
            "there was a posting, it may no longer be active.  If you're interested in pursuing a Ph.D. program\n",
            "in ecohydrology and remote sensing, I recommend searching for current job openings on websites like\n",
            "AcademicJobs.net, HigherEdJobs.com, or university-specific job boards. You can also reach out to the\n",
            "department of environmental science or geography at South Dakota School of Mines directly to inquire\n",
            "about potential graduate programs or research opportunities.  Remember to always verify the\n",
            "authenticity and legitimacy of job postings before applying or sharing them with others.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Who sent the LinkedIn post for a Full-Stack Software Engineering Intern role for the IT Business System Engineering team in Fall 2024 and/or Spring 2025 Computer Science students?\"\n",
        "result = llm(prompt.format(text=text))\n",
        "print(fill(result.strip(), width=100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwdRJBCqASYp",
        "outputId": "df6cd89b-8389-4b04-a104-25affec8f284"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>user<|end_header_id|>  Who sent the LinkedIn post for a Full-\n",
            "Stack Software Engineering Intern role for the IT Business System Engineering team in Fall 2024\n",
            "and/or Spring 2025 Computer Science students?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "I'm happy to help you with your question! However, I need more information. Can you please provide\n",
            "me with more context or details about the LinkedIn post you're referring to? Such as:  * The company\n",
            "name or industry? * The specific job title \"Full-Stack Software Engineering Intern\"? * Any other\n",
            "relevant keywords or phrases from the post?  This will help me narrow down my search and try to find\n",
            "the correct answer for you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"After how many years did Seth Ingall serve before depart from GEICO in spring of 2024?\"\n",
        "result = llm(prompt.format(text=text))\n",
        "print(fill(result.strip(), width=100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lpyRtIBAhbx",
        "outputId": "6374409a-330e-4256-c516-409e78eaa83f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>user<|end_header_id|>  After how many years did Seth Ingall\n",
            "serve before depart from GEICO in spring of\n",
            "2024?<|eot_id|><|start_header_id|>assistant<|end_header_id|> I apologize, but I couldn't find any\n",
            "information on a person named Seth Ingall serving at GEICO or departing the company in the spring of\n",
            "2024. It's possible that you may have incorrect or outdated information. If you could provide more\n",
            "context or clarify who Seth Ingall is and what his role was at GEICO, I'd be happy to try and help\n",
            "you further.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"What color are my shoes today?\"\n",
        "result = llm(prompt.format(text=text))\n",
        "print(fill(result.strip(), width=100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf63--oqA5g2",
        "outputId": "66589028-a655-49d4-eede-43748494f031"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>user<|end_header_id|>  What color are my shoes\n",
            "today?<|eot_id|><|start_header_id|>assistant<|end_header_id|> I'm just an AI, I don't have the\n",
            "ability to see or know what you're wearing. I can only respond based on our conversation. Since\n",
            "we've just started talking, I don't have any information about your shoes. Can you tell me what\n",
            "color they are?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2SNJZEtlDo1"
      },
      "source": [
        "# 5. Create a LangChain-based RAG system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "z8Y3YnRjJGEL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54ce8998-3d8f-451d-f418-33730deda0f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "links = []\n",
        "links.append(\"https://www.linkedin.com/posts/robschluensen_hello-fall-2024-andor-spring-2025-computer-activity-7191611032388132864-q8J3?utm_source=combined_share_message&utm_medium=member_desktop\")\n",
        "links.append(\"https://www.linkedin.com/posts/seth-ingall-20ab71226_last-fall-after-more-than-3-decades-of-service-activity-7193585428199809024-gJhT?utm_source=combined_share_message&utm_medium=member_desktop\")\n",
        "links.append(\"https://www.linkedin.com/posts/costafilhoe_fully-funded-phd-student-position-at-south-activity-7184803939345727488-pUDS?utm_source=combined_share_message&utm_medium=member_desktop\")\n",
        "links.append(\"https://www.linkedin.com/posts/xiao-kuang-9aa578184_scientist-xiao-kuang-activity-7193411289589723137-vD7O?utm_source=combined_share_message&utm_medium=member_desktop\")\n",
        "links.append(\"https://www.linkedin.com/posts/seungdeog-choi-b0a7246_pees-lab-activity-7193383940835995648-b1cp?utm_source=combined_share_message&utm_medium=member_desktop\")\n",
        "web_loader = UnstructuredURLLoader(\n",
        "    urls=links, mode=\"elements\", strategy=\"fast\",\n",
        "    )\n",
        "web_doc = web_loader.load()\n",
        "updated_web_doc = filter_complex_metadata(web_doc)\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2048, chunk_overlap=512)\n",
        "chunked_web_doc = text_splitter.split_documents(updated_web_doc)\n",
        "embeddings = HuggingFaceEmbeddings() # default model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
        "db_web = FAISS.from_documents(chunked_web_doc, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Providing my Prompts to the RAG System"
      ],
      "metadata": {
        "id": "vqsL2l42bxpK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxfNkw_PnItp",
        "outputId": "427aa1c7-2f85-4cb3-b6d3-4ee5b3e08199"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5 ¬µs, sys: 0 ns, total: 5 ¬µs\n",
            "Wall time: 7.87 ¬µs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "prompt_template_llama3 = \"\"\"\n",
        "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "\n",
        "Use the following context to answer the question at the end. Do not use any other information. If you can't find the relevant information in the context, just say you don't have enough information to answer the question. Don't try to make up an answer.\n",
        "\n",
        "{context}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\"\"\"\n",
        "\n",
        "prompt_template=prompt_template_llama3\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
        "Chain_web = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=db_web.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={'k': 10, 'score_threshold': 0.1}),\n",
        "    chain_type_kwargs={\"prompt\": prompt},\n",
        ")\n"
      ],
      "metadata": {
        "id": "p1S7nQqbgLRl"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj-yQeYIH209",
        "outputId": "518ac795-eff4-43cb-d0a4-dc2bee20add8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>  Use the following context to answer the\n",
            "question at the end. Do not use any other information. If you can't find the relevant information in\n",
            "the context, just say you don't have enough information to answer the question. Don't try to make up\n",
            "an answer.  LinkedIn  LinkedIn  LinkedIn  LinkedIn  LinkedIn  Hello Fall 2024 and/or Spring 2025\n",
            "Computer Science students.  I have 1 remaining Full-Stack Software Engineering Intern role for the\n",
            "IT Business System Engineering team.  The impact you will have: Work with the IT Business System\n",
            "Engineering team to roll out new features and processes to help several teams such as HR, Finance\n",
            "and Customer Success. Participate in full Development Lifecycle: design, development, testing,\n",
            "documentation and operations in production environment. Build customized applications with a high\n",
            "degree of reliability, scalability and security.  What we look for: You will graduate in Fall 2024\n",
            "or Spring 2025 with a degree in Computer Science, Engineering or Information Systems. You have\n",
            "implementation skills with a general purpose program language such as Python, Java, or C++. You have\n",
            "good knowledge of algorithms, data structures and OOP principles. You are excited to solve ambiguous\n",
            "problems with a collaborative team. You are excited to solve unique business problems and\n",
            "participate in a collaborative team environment.  https://lnkd.in/g9RFpMAX  Actively seeking\n",
            "Internship opportunities for Summer 2024 | MCS student @ASU | 4 YOE | Former HERE Technologies &\n",
            "Siemens Limited | FullStack Developer | Published Author  Hi Rob, I am interested in Full-Stack\n",
            "Software Engineering Intern opportunity. Email: ktalesra3@gatech.edu Resume:\n",
            "https://drive.google.com/file/d/1s_Wr6apqwQFcV3Os9W7UmY4r-kLLqONp/view?usp=sharing  Thank you all\n",
            "for the referrals and all the great students interested in applying.  üòÄ  Please apply here and we'll\n",
            "follow up with you shortly. https://www.databricks.com/company/careers/integration-data-engineering-\n",
            "and-applications/it-software-engineering-intern-2024-6955458002?gh_jid=6955458002  Actively seeking\n",
            "summer 2024 Internships | MS CS at Georgia Tech | Ex - Akamai\n",
            "Technologies<|eot_id|><|start_header_id|>user<|end_header_id|>  Who sent the LinkedIn post for a\n",
            "Full-Stack Software Engineering Intern role for the IT Business System Engineering team in Fall 2024\n",
            "and/or Spring 2025 Computer Science students?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "According to the provided text, it is not explicitly stated who sent the LinkedIn post. The post\n",
            "appears to be from someone actively seeking internship opportunities, but their name is not\n",
            "mentioned.\n"
          ]
        }
      ],
      "source": [
        "query = \"Who sent the LinkedIn post for a Full-Stack Software Engineering Intern role for the IT Business System Engineering team in Fall 2024 and/or Spring 2025 Computer Science students?\"\n",
        "result = Chain_web.invoke(query)\n",
        "print(fill(result['result'].strip(), width=100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfraMfszR6BU",
        "outputId": "defc6e83-139f-4c6a-af19-2f5dfdb3ddf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>  Use the following context to answer the\n",
            "question at the end. Do not use any other information. If you can't find the relevant information in\n",
            "the context, just say you don't have enough information to answer the question. Don't try to make up\n",
            "an answer.  Congrats Seth on your career at GEICO and a well deserved hiatus 30 years later, which I\n",
            "am sure will be short. Can't wait to learn about what comes next. All the best.  Seth Ingall\n",
            "Operational Executive | Chief Claims Officer | Chief Legal Officer | Strategic Corporate Leader and\n",
            "Former GEICO Executive\n",
            "1mo\n",
            "Report this post\n",
            "Congratulations!\n",
            "Joe Pusateri                                                     Chief Marketer | Performance &\n",
            "Brand Marketing VP  | ROI-minded Leader | Omnichannel Advertiser | Passionate Team Builder | DEI\n",
            "Advocate | Ex-GEICO\n",
            "1mo                                                                    Edited  Congratulations,\n",
            "Seth. Your dedication and commitment to our associates, our customers and our company over those 38\n",
            "years was impressive. I always admired and respected your relentless and passionate drive to deliver\n",
            "profitable growth.  You had a positive impact on so many associates lives, including mine. I\n",
            "appreciated your mentoring, guidance and counsel as a new RVP. Your legacy as a strong GEICO leader\n",
            "is cemented. You will be missed. Look forward to hearing what‚Äôs next for you. Let‚Äôs keep in touch.\n",
            "Operations Manager at GEICO  Seth - you were always one of my favorite senior leaders to work with\n",
            "and I miss our time working together. I sincerely appreciated your candor, sense of humor, guidance\n",
            "and commitment to doing what was best for GEICO and our customers. I wish you nothing but the best\n",
            "and know that whomever you work with in the future will be very fortunate.  Last fall, after more\n",
            "than 3 decades of service including 20 years on the executive team, I announced my anticipated\n",
            "departure from GEICO in the spring of 2024.¬†¬†This was not a decision I reached easily.  However, I\n",
            "leave knowing my lengthy transition allowed GEICO to recruit a talented successor who is now in\n",
            "place to lead the teams going forward.¬†   GEICO associates are some of the most knowledgeable,\n",
            "hardest working, tenacious, and kindest colleagues one can find.¬†¬†Together, and with many other\n",
            "current and former great executives, we built a market leader and incredible company that will\n",
            "continue its path towards growth and profit.  Thanks to all of you for trusting us in making GEICO a\n",
            "force in the insurance space.¬†   There are so many stories that I could tell about the people that\n",
            "joined me along the way, and we always managed to inject some fun in our work.   What‚Äôs next for\n",
            "me?¬†¬†More to come as I sort through the different opportunities and possibilities.¬†¬†Don‚Äôt hesitate\n",
            "to reach out, and please keep in touch.  Seth Ingall  To one of my favorite leaders - thanks for\n",
            "being there for the near entirety of my career at GEICO. Specifically, you were there for me during\n",
            "my lowest low and years and years later you still cared enough to reach out to me and council me\n",
            "when I was debating making a significant career change. You always motivated me to work hard and\n",
            "know my stuff, and we always had a laugh when we were together. I‚Äôm lucky to know you.\n",
            "Congratulations, Seth!  Congratulations Seth on your retirement from GEICO.  Best of luck in\n",
            "whatever you decide is next.  I have to say though being Grandpa and having 6 Saturdays and one\n",
            "Sunday a week is pretty darn good, so definitely live that life for a bit before you decide to go\n",
            "back to work üòÅ.  You know between Greg & I you have at least 2 beaches you can come visit..\n",
            "Operational Executive | Chief Claims Officer | Chief Legal Officer | Strategic Corporate Leader and\n",
            "Former GEICO Executive<|eot_id|><|start_header_id|>user<|end_header_id|>  After how many years did\n",
            "Seth Ingall serve before depart from GEICO in spring of\n",
            "2024?<|eot_id|><|start_header_id|>assistant<|end_header_id|> According to the text, Seth Ingall\n",
            "served for \"more than 30 years\" before announcing his departure from GEICO in the spring of 2024.\n",
            "CPU times: user 8.49 s, sys: 26.7 ms, total: 8.52 s\n",
            "Wall time: 8.6 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "query = \"After how many years did Seth Ingall serve before depart from GEICO in spring of 2024?\"\n",
        "result = Chain_web.invoke(query)\n",
        "print(fill(result['result'].strip(), width=100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWgQgd8FJcBm",
        "outputId": "8f41ffce-e365-4bf1-c544-9d5b32a7d0ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>  Use the following context to answer the\n",
            "question at the end. Do not use any other information. If you can't find the relevant information in\n",
            "the context, just say you don't have enough information to answer the question. Don't try to make up\n",
            "an answer.  Opportunity for a Fully-Funded Ph.D. degree at South Dakota School of Mines\n",
            "--------------------------------------------------------------------------------------- I am pleased\n",
            "to announce that I am seeking a highly motivated individual for a fully-funded Ph.D. student\n",
            "position in ecohydrology and remote sensing, starting in Spring 2025 at South Dakota School of\n",
            "Mines, Rapid City, SD. The start date of this Ph.D. program and research is January 13, 2025.\n",
            "Application Deadline:  The deadline for submissions is May 10, 2024.  Interested candidates are\n",
            "invited to apply by visiting the following link: https://shorturl.at/hzDT6. Please, complete the\n",
            "screening questionnaire and upload your most recent CV. Applications will be reviewed on a rolling\n",
            "basis, and only candidates shortlisted for further consideration will be contacted via email to\n",
            "schedule a Zoom interview. The interviews will start on May 1, 2024.  Additional Information:   For\n",
            "more details about this position, refer to the attached informational flyer. Please, share this\n",
            "flyer with your professional contacts who might be interested in joining my upcoming water resources\n",
            "research program at South Dakota School of Mines.  #phd #research #hydrology #remotesensing\n",
            "#phdopportunity #hiring #PhDJobs #phdpositions #phdresearch  Incoming Assistant Professor at South\n",
            "Dakota Mines\n",
            "3w                                                                    Edited\n",
            "Opportunity for a Fully-Funded Ph.D. degree at South Dakota School of Mines\n",
            "--------------------------------------------------------------------------------------- I am pleased\n",
            "to announce that I am seeking a highly motivated individual for a fully-funded Ph.D. student\n",
            "position in ecohydrology and remote sensing, starting in Spring 2025 at South Dakota School of\n",
            "Mines, Rapid City, SD. The start date of this Ph.D. program and research is January 13, 2025.\n",
            "Application Deadline:  The deadline for submissions is May 10, 2024.  Interested candidates are\n",
            "invited to apply by visiting the following link: https://shorturl.at/hzDT6. Please, complete the\n",
            "screening questionnaire and upload your most recent CV. Applications will be reviewed on a rolling\n",
            "basis, and only candidates shortlisted for further consideration will be contacted via email to\n",
            "schedule a Zoom interview. The interviews will start on May 1, 2024.  Additional Information:   For\n",
            "more details about this position, refer to the attached informational flyer. Please, share this\n",
            "flyer with your professional contacts who might be interested in joining my upcoming water resources\n",
            "research program at South Dakota School of Mines.  #phd #research #hydrology #remotesensing\n",
            "#phdopportunity #hiring #PhDJobs #phdpositions #phdresearch  LinkedIn  LinkedIn  LinkedIn  LinkedIn\n",
            "LinkedIn  Edson Costa-Filho, Ph.D.                                                     Incoming\n",
            "Assistant Professor at South Dakota Mines\n",
            "4d                                                                    Edited\n",
            "Report this post\n",
            "Last week to apply for this fully funded PhD position in ecohydrology and satellite remote sensing.\n",
            "The deadline for applications is May 10, 2024. #phd #research #hydrology #remotesensing\n",
            "Edson Costa-Filho, Ph.D.                                                     Incoming Assistant\n",
            "Professor at South Dakota Mines\n",
            "3w                                                                    Edited  Associate Professor at\n",
            "Mississippi State University  Incoming Assistant Professor at South Dakota\n",
            "Mines<|eot_id|><|start_header_id|>user<|end_header_id|>  Who sent the LinkedIn post 3 weeks ago in\n",
            "April 2024 for a fully-funded Ph.D. student position in ecohydrology and remote sensing, starting in\n",
            "Spring 2025 at South Dakota School of Mines, Rapid City,\n",
            "SD.?<|eot_id|><|start_header_id|>assistant<|end_header_id|> According to the provided context, it\n",
            "was Edson Costa-Filho, Ph.D., who sent the LinkedIn post 3 weeks ago in April 2024 for a fully-\n",
            "funded Ph.D. student position in ecohydrology and remote sensing, starting in Spring 2025 at South\n",
            "Dakota School of Mines, Rapid City, SD.\n",
            "CPU times: user 16.6 s, sys: 51.5 ms, total: 16.7 s\n",
            "Wall time: 17 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "query = \"Who sent the LinkedIn post 3 weeks ago in April 2024 for a fully-funded Ph.D. student position in ecohydrology and remote sensing, starting in Spring 2025 at South Dakota School of Mines, Rapid City, SD.?\"\n",
        "result = Chain_web.invoke(query)\n",
        "print(fill(result['result'].strip(), width=100))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What color are my shoes today?\"\n",
        "result = Chain_web.invoke(query)\n",
        "print(fill(result['result'].strip(), width=100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRnPktGuZQvj",
        "outputId": "2b22f741-28c8-400c-e651-8dbd67e10ee3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/vectorstores.py:330: UserWarning: Relevance scores must be between 0 and 1, got [(Document(page_content='7h', metadata={'category_depth': 0, 'page_number': 1, 'filetype': 'text/html', 'url': 'https://www.linkedin.com/posts/xiao-kuang-9aa578184_scientist-xiao-kuang-activity-7193411289589723137-vD7O?utm_source=combined_share_message&utm_medium=member_desktop', 'category': 'Title'}), -0.05315685263312386), (Document(page_content='51', metadata={'page_number': 1, 'parent_id': 'e2bd70c57397a0eace894ed643a6f12c', 'filetype': 'text/html', 'url': 'https://www.linkedin.com/posts/costafilhoe_fully-funded-phd-student-position-at-south-activity-7184803939345727488-pUDS?utm_source=combined_share_message&utm_medium=member_desktop', 'category': 'UncategorizedText'}), -0.06430132231637442), (Document(page_content='74', metadata={'page_number': 1, 'parent_id': '66f96e8a08a40a888e3f271b5226a43c', 'filetype': 'text/html', 'url': 'https://www.linkedin.com/posts/xiao-kuang-9aa578184_scientist-xiao-kuang-activity-7193411289589723137-vD7O?utm_source=combined_share_message&utm_medium=member_desktop', 'category': 'UncategorizedText'}), -0.07170365761403974), (Document(page_content='4 Posts', metadata={'category_depth': 1, 'page_number': 1, 'parent_id': '06b696bd83206c6d359ca3abd28c2562', 'filetype': 'text/html', 'url': 'https://www.linkedin.com/posts/seungdeog-choi-b0a7246_pees-lab-activity-7193383940835995648-b1cp?utm_source=combined_share_message&utm_medium=member_desktop', 'category': 'ListItem'}), -0.07212529468654272), (Document(page_content='13h', metadata={'page_number': 1, 'parent_id': 'e4ec3149091fc5c3355652d13b161df9', 'filetype': 'text/html', 'url': 'https://www.linkedin.com/posts/seungdeog-choi-b0a7246_pees-lab-activity-7193383940835995648-b1cp?utm_source=combined_share_message&utm_medium=member_desktop', 'category': 'UncategorizedText'}), -0.0805893090981975), (Document(page_content='5 Posts', metadata={'category_depth': 1, 'page_number': 1, 'parent_id': '93bf79e29ddfde9da4d4d3e9cccc1162', 'filetype': 'text/html', 'url': 'https://www.linkedin.com/posts/xiao-kuang-9aa578184_scientist-xiao-kuang-activity-7193411289589723137-vD7O?utm_source=combined_share_message&utm_medium=member_desktop', 'category': 'ListItem'}), -0.08229153601585537), (Document(page_content='23h', metadata={'page_number': 1, 'parent_id': '66cd97d36e9612c4977e201eba3a49c4', 'filetype': 'text/html', 'url': 'https://www.linkedin.com/posts/seungdeog-choi-b0a7246_pees-lab-activity-7193383940835995648-b1cp?utm_source=combined_share_message&utm_medium=member_desktop', 'category': 'UncategorizedText'}), -0.0840884247552689), (Document(page_content='23h', metadata={'page_number': 1, 'parent_id': 'cf4f207af0a2d9e1340359ba2cfc15b1', 'filetype': 'text/html', 'url': 'https://www.linkedin.com/posts/seth-ingall-20ab71226_last-fall-after-more-than-3-decades-of-service-activity-7193585428199809024-gJhT?utm_source=combined_share_message&utm_medium=member_desktop', 'category': 'UncategorizedText'}), -0.0840884247552689), (Document(page_content='23h', metadata={'page_number': 1, 'parent_id': '9e76540dd5f1ad02b711a01f5d40d1fa', 'filetype': 'text/html', 'url': 'https://www.linkedin.com/posts/seth-ingall-20ab71226_last-fall-after-more-than-3-decades-of-service-activity-7193585428199809024-gJhT?utm_source=combined_share_message&utm_medium=member_desktop', 'category': 'UncategorizedText'}), -0.0840884247552689), (Document(page_content='Comment', metadata={'category_depth': 0, 'page_number': 1, 'filetype': 'text/html', 'url': 'https://www.linkedin.com/posts/xiao-kuang-9aa578184_scientist-xiao-kuang-activity-7193411289589723137-vD7O?utm_source=combined_share_message&utm_medium=member_desktop', 'category': 'Title'}), -0.08864028439444538)]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/vectorstores.py:342: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.1\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>  Use the following context to answer the\n",
            "question at the end. Do not use any other information. If you can't find the relevant information in\n",
            "the context, just say you don't have enough information to answer the question. Don't try to make up\n",
            "an answer.  <|eot_id|><|start_header_id|>user<|end_header_id|>  What color are my shoes\n",
            "today?<|eot_id|><|start_header_id|>assistant<|end_header_id|> I don't have enough information to\n",
            "answer that question. I'm a large language model, I don't have access to your physical appearance or\n",
            "surroundings, so I wouldn't know what color your shoes are today.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "50facd2c87c242e0ac0bf86a3e405d98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb0941ce1a8642d7a2e4d74a9dfc62a2",
              "IPY_MODEL_2a4d9448a7384dc693b18352c3e20356",
              "IPY_MODEL_bf4f67aaed95470a976e9a62e11ff313"
            ],
            "layout": "IPY_MODEL_4fb431e30a8b42cea90de3b269d1bddb"
          }
        },
        "fb0941ce1a8642d7a2e4d74a9dfc62a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1d205e34a0347b293a7d5975211ca0a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_52b89f64e12a463fb5cffa78438005a4",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "2a4d9448a7384dc693b18352c3e20356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0cb6df62cd141338969111d4440e7bf",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b76b87424b9f4b70b0c9e9c55db5e584",
            "value": 4
          }
        },
        "bf4f67aaed95470a976e9a62e11ff313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a084fdb4f194e60a7ee2a705834b3a6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_629627ef06c647c08f5786696de8d3ef",
            "value": "‚Äá4/4‚Äá[01:28&lt;00:00,‚Äá18.88s/it]"
          }
        },
        "4fb431e30a8b42cea90de3b269d1bddb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1d205e34a0347b293a7d5975211ca0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52b89f64e12a463fb5cffa78438005a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0cb6df62cd141338969111d4440e7bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b76b87424b9f4b70b0c9e9c55db5e584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a084fdb4f194e60a7ee2a705834b3a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "629627ef06c647c08f5786696de8d3ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}